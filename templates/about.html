<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>About VigilantEye</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
  <style>
    body {
      background: linear-gradient(to right, #0f2027, #203a43, #2c5364);
      color: #fff;
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    .container {
      max-width: 900px;
      margin-top: 80px;
      background-color: #ffffff10;
      border-radius: 16px;
      padding: 40px;
      box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);
      backdrop-filter: blur(10px);
    }
    h1, h2 {
      font-weight: bold;
      color: #17a2b8;
    }
    p {
      font-size: 17px;
      line-height: 1.7;
      color: #e0e0e0;
    }
    nav.navbar {
      backdrop-filter: blur(12px);
      background-color: rgba(255, 255, 255, 0.05);
    }
  </style>
</head>
<body>

<nav class="navbar navbar-expand-lg navbar-dark bg-transparent px-4">
  <a class="navbar-brand" href="{{ url_for('index') }}">üõ°Ô∏è VigilantEye</a>
  <div class="ms-auto">
    {% if session.get('username') %}
      <span class="text-white me-3">üë§ {{ session['username'] }}</span>
      <a href="{{ url_for('logout') }}" class="btn btn-outline-light btn-sm">Logout</a>
    {% else %}
      <a href="{{ url_for('login') }}" class="btn btn-outline-light btn-sm me-2">Login</a>
      <a href="{{ url_for('signup') }}" class="btn btn-outline-info btn-sm">Sign Up</a>
    {% endif %}
  </div>
</nav>

<div class="container">
  <h1>About VigilantEye</h1>
  <hr class="text-white">
  <p>
    VigilantEye is an AI-powered malware detection platform specifically designed to scan animated GIF files for hidden threats.
    Cyber attackers are increasingly using steganography to embed malicious payloads inside media files like GIFs. These infected GIFs
    often bypass traditional antivirus tools undetected.
  </p>
  <p>
    Our solution leverages advanced <strong>CNN-based deep learning</strong> to classify whether a GIF is infected or clean. Additionally,
    it attempts to identify the exact <strong>type of embedded attack or payload</strong> ‚Äî such as appended JavaScript, shell commands,
    PHP backdoors, and more.
  </p>
  <p>
    With VigilantEye, we aim to provide:
    <ul>
      <li>üîç Real-time analysis of GIF files for suspicious code patterns</li>
      <li>üß† Deep learning inference trained on synthetic malware-injected datasets</li>
      <li>‚ö†Ô∏è Clear feedback to the user with detected methods and decoded payloads</li>
      <li>üõ°Ô∏è Protection against emerging steganographic threats</li>
    </ul>
  </p>
  <p>
    This project was developed as part of a final year academic project to explore novel ways of improving digital media security.
  </p>
</div>

</body>
</html>
